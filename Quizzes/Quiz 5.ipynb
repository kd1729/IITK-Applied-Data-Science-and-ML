{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1y00BqjpyTP"
   },
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YWHjWjtp9Bz"
   },
   "source": [
    "### Q. Generate Random points\n",
    "Write a function that takes parameters $r_1$, $r_2$, $n$ and generates random points $(x_1, x_2)$ as follows - \n",
    "- $n$ random points that lie within a circle with center at $(0, 0)$ and radius $r_1$ $\\rightarrow$ These points belong to class ```'inner'```\n",
    "- $n$ random points that lie outside circle with center at $(0, 0)$ and radius $r_1$ but inside circle with center at $(0, 0)$ and radius $r_2$ $\\rightarrow$ These points belong to class ```'outer'```\n",
    "\n",
    "The function gen_random should return $X$, $Cls$ :\n",
    "- $X$ is a numpy array of shape $(2n, 2)$ which has the $2n$ random points generated as above\n",
    "- $Cls$ is a numpy array of shape $(2n,)$ which contains the value of the class corresponding to each point in $X$ (values will be either ```'inner'``` or ```'outer'```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WWEUIetpA04"
   },
   "outputs": [],
   "source": [
    "def gen_random_points(r1, r2, n):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    r1 : float\n",
    "    r2 : float\n",
    "    n : int, number of points\n",
    "  Outputs:\n",
    "    X : numpy array, shape -> (2n, 2)\n",
    "    Cls : numpy array, shape -> (2n, )\n",
    "  \"\"\"\n",
    "  ### Write your code here\n",
    "  import numpy as np\n",
    "  import math, random\n",
    "\n",
    "  l=[]\n",
    "  l2=[]\n",
    "    \n",
    "  for i in range(n):\n",
    "        a1=[]\n",
    "        t = random.random()\n",
    "        u = random.random()\n",
    "        x=r1 * math.sqrt(t) * math.cos(2 * math.pi * u) \n",
    "        y=r1 * math.sqrt(t) * math.sin(2 * math.pi * u)\n",
    "        a1.append(x)\n",
    "        a1.append(y)\n",
    "        l.append(a1)\n",
    "        l2.append(\"inner\")\n",
    "        \n",
    "  for i in range(n):\n",
    "        a2=[]\n",
    "        t= random.uniform(r1/r2,1)\n",
    "        u = random.random()\n",
    "        x=r2 * math.sqrt(t) * math.cos(2 * math.pi * u) \n",
    "        y=r2 * math.sqrt(t) * math.sin(2 * math.pi * u)\n",
    "        a2.append(x)\n",
    "        a2.append(y)\n",
    "        l.append(a2)\n",
    "        l2.append(\"outer\")\n",
    "  X = np.asarray(l)\n",
    "  Cls=np.asarray(l2)\n",
    "            \n",
    "  return X,Cls     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQEovtnWvF1E"
   },
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZnBaClDvJbp"
   },
   "source": [
    "### Q. One-hot encode\n",
    "Write a function that takes a numpy array $Cls$ of shape $(n, )$ which contains class labels of $n$ samples of data and creates a numpy array, $Y_d$ of shape $(n, \\text{unique})$ containing 1-hot representations of the $n$ samples. Here $\\text{unique}$ is the number of unique classes in $Cls$. <br>\n",
    "The function should return two values - \n",
    "- $Y_d$ - numpy array of shape $(n, \\text{unique})$ with 1-hot representations\n",
    "- ```cls_order``` - numpy array of shape $(\\text{unique}, )$ which contains the labels of the classes in the order in which they occur in the 1-hot representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WLB75bffvIne"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(Cls):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    Cls: numpy array, shape: (n, ) contains class labels of n data samples\n",
    "  Outputs:\n",
    "    Yd : numpy array of shape (n, unique)\n",
    "    cls_order: numpy array of shape(unique, )\n",
    "  \"\"\"\n",
    "  ### Write your code here\n",
    "  import numpy as np\n",
    "  from sklearn.preprocessing import LabelEncoder\n",
    "  from sklearn.preprocessing import OneHotEncoder  \n",
    "  \n",
    "  label_encoder = LabelEncoder()\n",
    "  integer_encoded = label_encoder.fit_transform(Cls)\n",
    "  onehot_encoder = OneHotEncoder(sparse=False)\n",
    "  integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "  Yd = onehot_encoder.fit_transform(integer_encoded)\n",
    "  \n",
    "  lst=list(set(Cls))\n",
    "  lst.sort()\n",
    "  cls_order=np.asarray(lst)\n",
    "  \n",
    "  return Yd,cls_order\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFD0WNUbzYUo"
   },
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTczqgGRzZ-K"
   },
   "source": [
    "### Q. Softmax\n",
    "Write a function that takes a vector (numpy array of shape $(f,)$) - $(y_{in})$ and returns the result vector (numpy array of shape $(f,)$) - $(y_{out})$ of applying the softmax non-linearity to it. <br>\n",
    "$$\n",
    "y_{out}^{i} = \\frac{e^{y_{in}^{i}}}{\\sum_{i=1}^{f}e^{y_{in}^{i}}}\n",
    "$$ \n",
    "\n",
    "where $y^{i}$ refers to the $i^{th}$ component of vector $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6jF41px0EAD"
   },
   "outputs": [],
   "source": [
    "def softmax(y_in):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    y_in : numpy array of shape (f, ), input vector \n",
    "  Outputs:\n",
    "    y_out : numpy array of shape(f, ), output vector\n",
    "  \"\"\"\n",
    "  ### Write your code here\n",
    "    \n",
    "  import math\n",
    "  import numpy as np\n",
    "  n=len(y_in)\n",
    "  sm=0\n",
    "  for i in range(n):\n",
    "      sm+=math.exp(y_in[i])  \n",
    "  \n",
    "  y=[]\n",
    "  for i in range(n):\n",
    "    y.append(math.exp(y_in[i])/sm)\n",
    "   \n",
    "  y_out=np.asarray(y)\n",
    "    \n",
    "  return y_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bymfyiNKzoep"
   },
   "source": [
    "## 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgvyBiO2zttQ"
   },
   "source": [
    "### Q. Standardize\n",
    "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{stdz}$  after standardizing $X$ where\n",
    "$$\n",
    "  X_{stdz}^i = \\frac{X^i - \\mu(X)}{\\sigma(X)}\n",
    "$$\n",
    "where $\\mu(X)$ is the feature-wise mean of all samples in $X$ and $\\sigma(X)$ is feature-wise standard deviation of all samples in $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wLIHeN-3G1x"
   },
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    X: numpy array of shape (n, f)\n",
    "  Outputs:\n",
    "    X_stdz : numpy array of shape (n, f)\n",
    "  \"\"\"\n",
    "  ### Write your code here\n",
    "  import statistics\n",
    "  import numpy as np\n",
    "  n,f = X.shape\n",
    "  for i in range(f):\n",
    "        mean=statistics.mean(X[:,i])\n",
    "        stnd_dev=statistics.stdev(X[:,i])\n",
    "        for j in  range(n):\n",
    "            X[j,i]=(X[j,i]-mean)/stnd_dev\n",
    "  \n",
    "  X_stdz=np.asarray(X)\n",
    "  return X_stdz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kazu6ZCf7xVU"
   },
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2oPGUWp37y63"
   },
   "source": [
    "### Q. Normalize\n",
    "Write a function that takes input dataset $X$ of shape $(n, f)$ and returns dataset $X_{normd}$  after normalizing $X$ where\n",
    "$$\n",
    "  X_{normd}^i = \\frac{X^i - \\min(X)}{max(X) - min(X)}\n",
    "$$\n",
    "where $\\max(X)$ is the feature-wise maximum of all samples in $X$ and $min(X)$ is feature-wise minimum of all samples in $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rC3cuVxU-vSp"
   },
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "  \"\"\"\n",
    "  Inputs:\n",
    "    X: numpy array of shape (n, f)\n",
    "  Outputs:\n",
    "    X_normd : numpy array of shape (n, f)\n",
    "  \"\"\"\n",
    "   ### Write your code here\n",
    "  import numpy as np\n",
    "  n,f = X.shape\n",
    "  for i in range(f):\n",
    "    min_=min(X[:,i])\n",
    "    max_=max(X[:,i])\n",
    "    for j in  range(n):\n",
    "            X[j,i] = (X[j,i] - min_) / (max_- min_)\n",
    "    \n",
    "  X_normd=np.asarray(X)         \n",
    "  return X_normd  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMnWwBaV9cZ6v+NO3ciRy6",
   "collapsed_sections": [],
   "name": "Quiz 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
